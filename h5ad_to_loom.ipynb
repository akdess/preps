{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convertion of h5ad to loom & Tokenization\n",
    "#### This is always the first step of feeding a h5ad file into a Geneformer-based model, no matter it is to fine-tune the foundational model or to apply prediction/extract embeddings.\n",
    "\n",
    "#### Geneformer tokenizer requires ENSG IDs instead of gene symbols. This notebook uses the GProfiler package to match ENSG IDs with gene symbols automatically, which is a online searching process and may be prohibited/interrupted when running on server. Therefore, this notebook is preferably running locally. \n",
    "\n",
    "#### The equivalent python version of this notebook is h5ad_to_loom.py, where ENSG IDs are supposed to be ready in the h5ad file and online searching is no longer needed. Therefore, h5ad_to_loom.py is preferably running on server, especially when the h5ad file is too large to load locally."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scanpy as sc\n",
    "from scipy.io import mmread\n",
    "import torch\n",
    "import loompy\n",
    "from gprofiler import GProfiler\n",
    "from geneformer import TranscriptomeTokenizer\n",
    "\n",
    "\n",
    "os.environ['PYTHONHASHSEED'] = '0'\n",
    "random.seed(0)\n",
    "np.random.seed(0)\n",
    "torch.manual_seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load genes, barcodes, and matrix if h5ad is unavailable, otherwise load h5ad directly \n",
    "name = 'allen'\n",
    "ref_directory = 'allen brain patchseq data of 385 cells human/'\n",
    "\n",
    "with open(ref_directory + 'genes.tsv') as f:\n",
    "    genes = f.read().rstrip().split('\\n')\n",
    "\n",
    "with open(ref_directory + 'barcodes.tsv') as f:\n",
    "    barcodes = f.read().rstrip().split('\\n')\n",
    "\n",
    "mat = mmread(ref_directory + 'matrix.mtx')\n",
    "df = pd.DataFrame.sparse.from_spmatrix(mat, index=genes, columns=barcodes).fillna(0)\n",
    "adata = sc.AnnData(df.T)\n",
    "adata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# name = 'WHB-10Xv3-Nonneurons-raw'\n",
    "# adata = sc.read_h5ad(f'allen_rnaseq/{name}.h5ad')\n",
    "# adata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure raw counts instead of log\n",
    "np.amax(adata.X.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and attach cell metadata\n",
    "index_col = 'CellID'\n",
    "df_ref_meta = pd.read_csv(ref_directory + 'meta.tsv', sep='\\t', index_col=index_col)\n",
    "df_ref_meta = df_ref_meta.loc[adata.obs_names, :]\n",
    "adata.obs = df_ref_meta.copy()\n",
    "adata.obs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Load additional gene metadata if necessary\n",
    "# df_genes = pd.read_csv('spatial_raw_data_input/gene_names.csv', header=None, index_col=0)\n",
    "# df_genes.index.name = None\n",
    "# df_genes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Load additional gene metadata if necessary\n",
    "# adata.var = df_genes.copy()\n",
    "# adata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adata.obs.to_excel('allen brain patchseq data of 385 cells human/meta.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = adata.var.copy()\n",
    "# df.index.name = 'ensembl_id'\n",
    "# df.to_excel('allen brain patchseq data of 385 cells human/features.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and filter cells in ephys dataset\n",
    "df_ephys = pd.read_csv(ref_directory + 'human_mouse_ephys_all_0127.csv', index_col='specimen_id')\n",
    "df_ephys = df_ephys.dropna(how='all') # drop cells whose ephys features are all none\n",
    "df_ephys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter adata cells\n",
    "adata = adata[adata.obs['SpecimenID'].isin(df_ephys.index.tolist())].copy()\n",
    "adata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Filter adata cells\n",
    "# c1 = adata.obs['Input.resistance.(MOhm)'].notna()\n",
    "# c2 = adata.obs['AP.amplitude.(mV)'].notna()\n",
    "# c3 = adata.obs['Max.number.of.APs'].notna()\n",
    "# adata = adata[c1 & c2 & c3].copy()\n",
    "# adata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save filtered adata\n",
    "adata.write(ref_directory + 'allen_283samples.h5ad')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save filtered ephys dataset\n",
    "df_ephys = df_ephys.loc[adata.obs['SpecimenID'].tolist(), :]\n",
    "df_ephys.to_csv(ref_directory + 'human_mouse_ephys_all_0127_sorted283humanOnly.csv')\n",
    "df_ephys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adata.obs['group'] = adata.obs['anatomical_division_label'].values # Designate one column as \"group\" that contains groups information for model finetuning\n",
    "adata.obs['isTumor'] = 0 # A trick related to finetuning: only those cells labeled with \"isTumor = 0\" are to be used for model finetuning\n",
    "adata.obs = adata.obs[['group', 'isTumor']].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adata.obs['group'] = adata.obs['anatomical_division_label'].values # Designate one column as \"group\" that contains groups information for model finetuning\n",
    "# adata.obs['isTumor'] = 0 # A trick related to finetuning: only those cells labeled with \"isTumor = 0\" are to be used for model finetuning\n",
    "# adata.obs = adata.obs[['group', 'isTumor', 'SpecimenID']].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Balance dataset among groups by subsampling, only performed when adata is to be used for model fine-tuning\n",
    "# cells = []\n",
    "# celltype_cells = {}\n",
    "# n_cells = 1000\n",
    "# for celltype, group in adata.obs.groupby('group'):\n",
    "#     cells_this_type = group.index.tolist()\n",
    "#     np.random.shuffle(cells_this_type)\n",
    "#     cells = cells + cells_this_type[:n_cells]\n",
    "#     celltype_cells[celltype] = cells_this_type[:n_cells]\n",
    "\n",
    "# np.random.shuffle(cells)\n",
    "# adata = adata[cells, :].copy()\n",
    "# adata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Online searching for ENSG IDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Search and get initial results\n",
    "gp = GProfiler(return_dataframe=True)\n",
    "df_genes_converted = gp.convert(organism='hsapiens',\n",
    "                                query=adata.var_names.tolist(),\n",
    "                                target_namespace='ENSG')\n",
    "df_genes_converted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One gene symbol can match multiple or none ENSG IDs\n",
    "# Drop duplicates and remove nones \n",
    "df_genes_converted = df_genes_converted[~df_genes_converted['incoming'].duplicated()]\n",
    "df_genes_converted = df_genes_converted[~df_genes_converted['converted'].isin([None, np.nan, 'None'])]\n",
    "df_genes_converted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save ENSG IDs, can be skipped\n",
    "df_genes_converted[['incoming', 'converted', 'name', 'description']].to_excel(f'{name}/{name}_convertedGenes.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter out those genes with no ENSG IDs\n",
    "adata = adata[:, df_genes_converted['incoming'].tolist()].copy()\n",
    "adata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add metadata required by tokenizer, don't change the feature names\n",
    "adata.var['ensembl_id'] = df_genes_converted['converted'].tolist()\n",
    "adata.obs['n_counts'] = np.sum(adata.X.toarray(), axis=1) # total read counts in each cell\n",
    "adata.obs['filter_pass'] = 1\n",
    "adata.obs['individual'] = adata.obs.index.tolist() # cell IDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Add metadata required by tokenizer (the case ENSG IDs are provided in the h5ad file)\n",
    "# adata.var['ensembl_id'] = adata.var.index.tolist()\n",
    "# adata.obs['n_counts'] = np.sum(adata.X.toarray(), axis=1) # total read counts in each cell\n",
    "# adata.obs['filter_pass'] = 1\n",
    "# adata.obs['individual'] = adata.obs['SpecimenID'].tolist() # cell IDs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving as loom & Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save as [name].loom in [ref_directory]\n",
    "data = adata.X.toarray().T\n",
    "df_row_metadata = adata.var.copy()\n",
    "df_col_metadata = adata.obs.copy()\n",
    "loompy.create(f'{ref_directory}{name}.loom', data, df_row_metadata.to_dict('list'), df_col_metadata.to_dict('list'))\n",
    "del adata, data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize [name].loom\n",
    "# Ensure [name].loom is the only loom file in [ref_directory]\n",
    "# Output is a folder [name].dataset in [ref_directory]\n",
    "tk = TranscriptomeTokenizer({'individual': 'individual', 'isTumor': 'isTumor', 'group': 'group', 'n_counts': 'n_counts'}, nproc=1)\n",
    "tk.tokenize_data(ref_directory, ref_directory, name)\n",
    "os.remove(f'{ref_directory}{name}.loom')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
